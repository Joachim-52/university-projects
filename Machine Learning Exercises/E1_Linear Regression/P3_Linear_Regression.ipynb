{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Demo\n",
    "\n",
    "## Linear Regression using the California Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# We will use an example dataset that comes with scikit learn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "california = fetch_california_housing(as_frame=True)\n",
    "print(california.data.shape)\n",
    "print(california.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(california.data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(california.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = california.frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = california.data\n",
    "y = california.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train and test set!\n",
    "We choose the test set to be 25% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will focus only on the features `['MedInc', 'Latitude', 'Longitude']` for simplicity. \n",
    "\n",
    "*Note*: In the real world, you would spend more time and brain power in this **feature selection** step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['MedInc', 'Latitude', 'Longitude']\n",
    "X_train = X_train[FEATURES]\n",
    "X_val = X_val[FEATURES]\n",
    "X_test = X_test[FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `pairplot` from the `seaborn` package (essentially a convenient `matplotlib` wrapper). This produces scatterplots between pairs of features. On the diagonal, we will plot a smoothed version of the *feature histogram*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "train_dataset = X_train.copy()[FEATURES]\n",
    "train_dataset['MedHouseVal'] = y_train\n",
    "sns.pairplot(train_dataset, kind=\"scatter\", diag_kind=\"kde\", plot_kws={'s': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a plot that shows the median house value as a function of (latitude, longitude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=train_dataset,\n",
    "    x='Longitude',\n",
    "    y='Latitude',\n",
    "    hue='MedHouseVal',\n",
    "    size='MedHouseVal',\n",
    "    palette='coolwarm',\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "plt.legend(title='MedHouseVal', loc='best')\n",
    "plt.title('Median house value depending of\\n their spatial location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add the constant (dummy) feature to our design matrix $X$ (for the `train`, `validation` and the `test` set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = X_train[FEATURES], X_val[FEATURES], X_test[FEATURES]\n",
    "X_train['Constant'] = 1\n",
    "X_val['Constant'] = 1\n",
    "X_test['Constant'] = 1\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the *loss*\n",
    "$$ \\mathcal{L}(\\theta) = \\frac{1}{N} \\| X \\theta - y \\|_2^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    squared_error = (y_pred - y_true)**2\n",
    "    return np.mean(squared_error)\n",
    "\n",
    "def loss(theta, X, y_true):\n",
    "    y_pred = X @ theta\n",
    "    return mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analytical solution can be calculated using the `pinv` function (pseudoinverse) from `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import pinv \n",
    "\n",
    "def compute_theta_star_and_losses(X_train: np.ndarray, y_train: np.ndarray, \n",
    "                                  X_val: np.ndarray, y_val: np.ndarray):\n",
    "    theta_star = pinv(X_train) @ y_train\n",
    "    print(f'{theta_star=}')\n",
    "    print(\"[Train] RMSE\", np.sqrt(loss(theta_star, X_train, y_train)))\n",
    "    print(\"[Validation] RMSE\", np.sqrt(loss(theta_star, X_val, y_val)))\n",
    "\n",
    "    return theta_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Regression (using a single feature and a bias term)\n",
    "\n",
    "To start, we will **only use the features** `MedInc` and the dummy feature `Constant` (to induce a bias term)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the analytical solution $\\theta^*_0$ (we use the subscript because we will compute other solutions soon). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_star_0 = compute_theta_star_and_losses(X_train[['MedInc', 'Constant']].to_numpy(), y_train.to_numpy(), \n",
    "                                             X_val[['MedInc', 'Constant']].to_numpy(), y_val.to_numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, our regression function $f_\\theta$ reads\n",
    "$$ f_{\\theta_0^*}(\\text{MedInc}) = 0.42 \\cdot \\text{MedInc} + 0.46$$\n",
    "\n",
    "Let's plot the regression line using the validation set (since it's 1D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medinc = X_val['MedInc'].to_numpy()\n",
    "x_0, x_max = np.array([0, 1]), np.array([np.max(medinc), 1])\n",
    "y_0 = x_0.T @ theta_star_0\n",
    "y_max = x_max.T @ theta_star_0\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(medinc, y_val.to_numpy(), s=5)\n",
    "plt.plot([0, np.max(medinc)], [y_0, y_max], c='r', linestyle='--', label='Regression line')\n",
    "plt.xlabel('MedInc')\n",
    "plt.ylabel('MedHouseVal')\n",
    "\n",
    "plt.title('MedInc vs MedHouseVal (Validation Set)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def plot_true_vs_pred(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse = np.mean((y_true - y_pred)**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    m = np.max([np.max(y_true), np.max(y_pred)])\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot([0, m], [0, m], c='r')\n",
    "    plt.scatter(y_pred, y_true, s=5)\n",
    "    plt.xlabel('y_pred')\n",
    "    plt.ylabel('y_true')\n",
    "    plt.title(f'Predictions vs True Targets\\nR^2 = {np.round(r2, 3)}, RMSE = {np.round(rmse, 3)}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can scatter plot `y_pred` vs `y_true`. If we used the *perfect* regressor (`y_pred == y_true` for all samples) this plot would show the *identity function* here ($45^\\circ$ line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = X_val[['MedInc', 'Constant']] @ theta_star_0\n",
    "plot_true_vs_pred(y_true=y_val, y_pred=y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we show the `R^2` score (coefficient of determination) for the validation set, which is defined as\n",
    "\n",
    "$$ R^2 = 1 - \\frac{\\sum_{i=1}^N (y^{(i)} - \\hat{y}^{(i)})^2}{\\sum_{i=1}^N (y^{(i)} - \\bar{y})^2} $$\n",
    "\n",
    "where $f_\\theta(\\mathbf{x}^{(i)}) = \\hat{y}^{(i)}$ are the predictions and $\\bar{y} = \\frac{1}{N} \\sum_{i=1}^N y_i$ is the mean of the target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more features!\n",
    "\n",
    "Let's add the features `Latitude` and `Longitude`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_star_1 = compute_theta_star_and_losses(X_train.to_numpy(), y_train.to_numpy(), \n",
    "                                             X_val.to_numpy(), y_val.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our regression function $f_\\theta$ now reads\n",
    "$$ f_{\\theta_1^*}(\\text{MedInc}, \\text{Lat}, \\text{Lon}) = 0.36 \\cdot \\text{MedInc} - 0.49 \\cdot \\text{Lat} - 0.50 \\cdot \\text{Lon} - 41.90$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = X_val @ theta_star_1\n",
    "plot_true_vs_pred(y_true=y_val, y_pred=y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using non-linear feature transformations\n",
    "\n",
    "We can transform our *features* (read $\\text{MedInc}, \\text{Lat}, \\text{Lon}$) using some non-linear functions $\\phi_{j=1,\\dots,M}$.\n",
    "\n",
    "For example, we will define $\\phi(\\text{Lat}, \\text{Lon}) = \\min(\\text{Distance to Los Angeles}, \\text{Distance to San Francisco})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians as rad\n",
    "\n",
    "EARTH_RADIUS = 6_378_000 # earth radius in meters\n",
    "san_francisco_coords = (rad(37.7749), rad(-122.4194)) # thanks OpenStreetMap!\n",
    "los_angeles_coords = (rad(34.0549), rad(-118.2426)) # thanks OpenStreetMap!\n",
    "\n",
    "def distance_to_city(coords, city):\n",
    "    assert city in ['los_angeles', 'san_francisco']\n",
    "    city_coords = los_angeles_coords if city == 'los_angeles' else san_francisco_coords\n",
    "\n",
    "    dists = []\n",
    "    for i in range(coords.shape[0]):\n",
    "        coords_row = (rad(coords[i, 0]), rad(coords[i, 1]))\n",
    "        dist = haversine_distances([coords_row, city_coords])\n",
    "        dist = (dist[0, 1] * EARTH_RADIUS) / 1000 # distance in km\n",
    "        dists.append(dist)\n",
    "    \n",
    "    return np.array(dists)\n",
    "\n",
    "# non-linear feature transform\n",
    "def add_min_city_distances_feature(X: pd.DataFrame):\n",
    "    coords = X[['Latitude', 'Longitude']].to_numpy()\n",
    "    dist_to_la = distance_to_city(coords, city='los_angeles')\n",
    "    dist_to_sf = distance_to_city(coords, city='san_francisco')\n",
    "    min_dists = np.vstack([dist_to_la, dist_to_sf]).min(axis=0)\n",
    "    X = X.copy() # create a copy such that we don't modify the input DataFrame\n",
    "    X['MinCityDistances'] =  min_dists\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = add_min_city_distances_feature(X_train)\n",
    "X_val_augmented = add_min_city_distances_feature(X_val)\n",
    "X_test_augmented = add_min_city_distances_feature(X_test)\n",
    "\n",
    "X_train_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_augmented['MinCityDistances'], y_train, s=5)\n",
    "plt.xlabel('MinCityDistances')\n",
    "plt.ylabel('MedHouseVal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_star_2 = compute_theta_star_and_losses(X_train_augmented, y_train, X_val_augmented, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have\n",
    "\n",
    "$$ f_{\\theta_2^*}(\\text{MedInc}, \\text{Lat}, \\text{Lon}) = 0.36 \\cdot \\text{MedInc} - 0.36 \\cdot \\text{Lat} - 0.38 \\cdot \\text{Lon} - 0.002 \\cdot \\phi(\\text{Lat}, \\text{Lon}) - 32.60$$\n",
    "\n",
    "This is *still linear* in $\\theta$ (it's just non-linear in the features)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val_2 = X_val_augmented @ theta_star_2\n",
    "plot_true_vs_pred(y_true=y_val, y_pred=y_pred_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some more non-linear feature transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some more non-linearly transformed features using *basis functions*!\n",
    "For example, \n",
    "$$\\phi_1(x) = x^2 \\qquad \\text{and} \\qquad \\phi_5(x) = \\exp\\left(\\frac{-(x - 1)^2}{2\\sigma^2}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1.\n",
    "\n",
    "basis_functions = [\n",
    "    # Polynomial basis functions\n",
    "    lambda x: x ** 2,\n",
    "    lambda x: x ** 3,\n",
    "    lambda x: x ** 4,\n",
    "    lambda x: x ** 5,\n",
    "\n",
    "    # Radial Basis Functions\n",
    "    lambda x: np.exp(-((x - 1) ** 2) / (2 * sigma ** 2)),\n",
    "    lambda x: np.exp(-((x - 3) ** 2) / (2 * sigma ** 2)),\n",
    "    lambda x: np.exp(-((x - 5) ** 2) / (2 * sigma ** 2)),\n",
    "    lambda x: np.exp(-((x - 7) ** 2) / (2 * sigma ** 2)),\n",
    "    lambda x: np.exp(-((x - 9) ** 2) / (2 * sigma ** 2)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_basis_function_features(X: np.ndarray):\n",
    "    X_nonlin_features = []\n",
    "    for basis_fn in basis_functions:\n",
    "        X_nonlin_features.append(basis_fn(X))\n",
    "    \n",
    "    X_nonlin_features = np.hstack(X_nonlin_features)\n",
    "    return np.hstack([X, X_nonlin_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented_basis = add_basis_function_features(X_train_augmented.to_numpy())\n",
    "X_val_augmented_basis = add_basis_function_features(X_val_augmented.to_numpy())\n",
    "X_test_augmented_basis = add_basis_function_features(X_test_augmented.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented_basis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_star_3 = compute_theta_star_and_losses(X_train_augmented_basis, y_train, X_val_augmented_basis, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val_3 = X_val_augmented_basis @ theta_star_3\n",
    "plot_true_vs_pred(y_true=y_val, y_pred=y_pred_val_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "So, which of the four models do we finally choose?\n",
    "\n",
    "+ $f_{\\theta_0^*}(\\text{MedInc})$ with $R^2 = 0.48$ and $RMSE = 0.83$\n",
    "    + Too simple, underfitting\n",
    "+ $f_{\\theta_1^*}(\\text{MedInc}, \\text{Lat}, \\text{Lon})$ with $R^2 = 0.59$ and $RMSE = 0.75$\n",
    "    + Decent fit, still simple and interpretable\n",
    "+ $f_{\\theta_2^*}(\\text{MedInc}, \\text{Lat}, \\text{Lon})$ with $R^2 = 0.60$ and $RMSE = 0.73$\n",
    "    + Decent fit, includes manual feature engineering, but is still interpretable\n",
    "+ $f_{\\theta_3^*}(\\text{MedInc}, \\text{Lat}, \\text{Lon})$ with $R^2 = 0.64$ and $RMSE = 0.69$\n",
    "    + Best fit, but is less interpretable (more complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick the third model $f_{\\theta_2^*}(\\text{MedInc}, \\text{Lat}, \\text{Lon})$ as our final model and calculate the test set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = X_test_augmented @ theta_star_2\n",
    "plot_true_vs_pred(y_true=y_test, y_pred=y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: We do not touch the test set until the very end of our model selection process!\n",
    "\n",
    "We don't want to use the test set to make *any* decisions about our model. It should only be used to assess the final model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('ml_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ca8060acd9adfae9bb5790ded9a2186afb83e1dbce524319b421a3eb6d028d9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
