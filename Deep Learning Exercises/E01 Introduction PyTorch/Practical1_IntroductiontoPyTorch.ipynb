{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UHvUsRqzJAh_"},"outputs":[],"source":["!python --version"]},{"cell_type":"markdown","metadata":{"vscode":{"languageId":"markdown"},"id":"UE1ixE88JAiB"},"source":["# PyTorch Introduction\n","\n","This tutorial is based on the excellent tutorial from the [PyTorch website](https://pytorch.org/tutorials/beginner/basics/intro.html), written by Suraj Subramanian, Seth Juarez, Cassie Breviu, Dmitry Soshnikov and Ari Bornstein."]},{"cell_type":"markdown","metadata":{"id":"POe3v82UJAiB"},"source":["## Tensors"]},{"cell_type":"markdown","metadata":{"id":"hKRI_pYdJAiC"},"source":["+ Tensors are essentially **multidimensional arrays**.\n","+ Used in `PyTorch` to encode model inputs, outputs, and parameters.\n","+ Similar to NumPyâ€™s `ndarrays` but can run on **GPUs and hardware accelerators**.\n","+ Tensors and NumPy arrays can share the same memory, avoiding data copying.\n","+ Optimized for **automatic differentiation**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i5lTztjNJAiC"},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"SrgEgboQJAiC"},"source":["Creating a tensor from a multidimensional Python array:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehfaulxNJAiC"},"outputs":[],"source":["x = [[1, 2], [3, 4], [5, 6]]\n","\n","x_torch = torch.tensor(x)\n","x_torch"]},{"cell_type":"markdown","metadata":{"id":"eOgyDvZXJAiC"},"source":["... which is akin to how we create numpy arrays:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kK2kl2i1JAiD"},"outputs":[],"source":["x_np = np.array(x)\n","x_np"]},{"cell_type":"markdown","metadata":{"id":"o4MxZXLeJAiD"},"source":["We can create a torch tensor directly from a numpy array, which shares the same memory:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcDNWRQEJAiD"},"outputs":[],"source":["x_torch_from_np = torch.from_numpy(x_np)\n","x_torch_from_np"]},{"cell_type":"markdown","metadata":{"id":"xgjPXcUWJAiD"},"source":["We can also convert a tensor to a numpy array using the `.numpy()` method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GwQM5BMhJAiD"},"outputs":[],"source":["x_torch.numpy()"]},{"cell_type":"markdown","metadata":{"id":"AjOdzgXQJAiD"},"source":["### Tensor attributes: `dtype`, `shape`, and `device`"]},{"cell_type":"markdown","metadata":{"id":"U56E9_gyJAiE"},"source":["Tensors have a `dtype` attribute that specifies the data type of the elements in the tensor.\n","\n","Since the original list contains integers, the tensor is of type `torch.int64` (type inference).\n","The default type is `torch.float32`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AP5Ufa4LJAiE"},"outputs":[],"source":["x_torch.dtype"]},{"cell_type":"markdown","metadata":{"id":"mopQOnO7JAiE"},"source":["If we create a tensor from a list of *floats*, the tensor will be of type `torch.float32`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9w3Tqc_DJAiE"},"outputs":[],"source":["x_torch = torch.tensor([[1., 2.], [3., 4.], [5., 6.]])\n","x_torch.dtype"]},{"cell_type":"markdown","metadata":{"id":"UjpOYvetJAiE"},"source":["We can explictly set the dtype when constructing a tensor:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vgm5Nh9fJAiE"},"outputs":[],"source":["x_torch = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float64)\n","x_torch.dtype"]},{"cell_type":"markdown","metadata":{"id":"2vBr7QcqJAiE"},"source":["Like in `numpy`, each torch tensor has a `shape` attribute that describes the size of each dimension of the tensor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hIsX9IadJAiE"},"outputs":[],"source":["x_torch = torch.tensor([[1., 2.], [3., 4.], [5., 6.]])\n","print(x_torch)\n","print(f'\\nShape: {x_torch.shape}')"]},{"cell_type":"markdown","metadata":{"id":"6AmAbomyJAiF"},"source":["i.e., `x_torch` $\\in \\mathbb{R}^{3 \\times 2}$"]},{"cell_type":"markdown","metadata":{"id":"de-7pKJsJAiF"},"source":["By default, `torch` tensors are created on the CPU.\n","We can check which device the tensor is on using the `.device` attribute."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wlZ1D9pMJAiF"},"outputs":[],"source":["x_torch.device"]},{"cell_type":"markdown","metadata":{"id":"v0p6nZNvJAiF"},"source":["If we have a GPU, we can move it to the GPU using the `to` method:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTqp4lBuJAiF"},"outputs":[],"source":["DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","x_torch = x_torch.to(DEVICE)\n","x_torch.device"]},{"cell_type":"markdown","metadata":{"id":"zcvGNZRPJAiF"},"source":["### Creating Tensors with default values"]},{"cell_type":"markdown","metadata":{"id":"AdD5PhLgJAiG"},"source":["There are other convenient ways to create tensors:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3Gftp7uJAiG"},"outputs":[],"source":["ones = torch.ones(3, 2)\n","ones"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oypws84rJAiG"},"outputs":[],"source":["zeros = torch.zeros(3, 2)\n","zeros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7VWbgEmSJAiG"},"outputs":[],"source":["normal_samples = torch.randn(3, 2)\n","normal_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPNa7cLUJAiG"},"outputs":[],"source":["arange = torch.arange(6.)\n","arange"]},{"cell_type":"markdown","metadata":{"id":"R7kpKXkMJAiH"},"source":["If we already have a tensor and we want to create a new tensor with the same `shape`, `dtype`, and `device`, we can use the following methods:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l55EMkCpJAiH"},"outputs":[],"source":["ones = torch.ones_like(x_torch)\n","ones"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DunnmAiTJAiH"},"outputs":[],"source":["zeros = torch.zeros_like(x_torch)\n","normal_samples = torch.randn_like(x_torch)"]},{"cell_type":"markdown","metadata":{"id":"m6jmok30JAiH"},"source":["### Reshaping\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"voDeAaZmJAiH"},"outputs":[],"source":["arange = torch.arange(8.)\n","print(arange)\n","print(f'\\nShape: {arange.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HioSaAcsJAiH"},"outputs":[],"source":["arange = arange.reshape(4, 2)\n","arange"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EjAsLMzMJAiH"},"outputs":[],"source":["arange = arange.reshape(2, 2, 2)\n","arange"]},{"cell_type":"markdown","metadata":{"id":"Fy_YPhBXJAiH"},"source":["### Indexing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xQkGMTbJAiH"},"outputs":[],"source":["tensor = torch.arange(16.).reshape(4, 4)\n","tensor"]},{"cell_type":"markdown","metadata":{"id":"rmSrBrB8JAiI"},"source":["Indexing works the same way as in `numpy`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2P7JF_KJAiI"},"outputs":[],"source":["tensor[2, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FLolnuujJAiI"},"outputs":[],"source":["print(f\"First row: {tensor[0, :]}\")\n","print(f\"First column: {tensor[:, 0]}\")\n","print(f\"Second column: {tensor[:, 1]}\")\n","print(f\"Last column: {tensor[:, -1]}\")"]},{"cell_type":"markdown","metadata":{"id":"1jAXhMBiJAiI"},"source":["### Operations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdQUiS4RJAiI"},"outputs":[],"source":["tensor"]},{"cell_type":"markdown","metadata":{"id":"gQ4zGTwuJAiI"},"source":["[Broadcast operation](https://pytorch.org/docs/stable/notes/broadcasting.html):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ggn4jbIhJAiI"},"outputs":[],"source":["t2 = tensor + 1.5\n","t2"]},{"cell_type":"markdown","metadata":{"id":"XJSPY4wxJAiI"},"source":["Add two tensors of same shape:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAsDd5FfJAiI"},"outputs":[],"source":["tensor + t2"]},{"cell_type":"markdown","metadata":{"id":"Ihh27eqCJAiI"},"source":["Component-wise product:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aICh9t2_JAiI"},"outputs":[],"source":["tensor * t2"]},{"cell_type":"markdown","metadata":{"id":"ng5VYQZ7JAiI"},"source":["We can *transpose* the tensor using the `T` method:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUTOHNcuJAiI"},"outputs":[],"source":["print(tensor)\n","print('\\n')\n","print(tensor.T)"]},{"cell_type":"markdown","metadata":{"id":"fuM3hWAEJAiI"},"source":["Matrix multiply:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7MMT76UJAiI"},"outputs":[],"source":["tensor.T @ tensor"]},{"cell_type":"markdown","metadata":{"id":"vf5v40vfJAiJ"},"source":["### Aggregation functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTKWonCHJAiJ"},"outputs":[],"source":["print(f'Sum: {torch.sum(tensor)}')\n","print(f'Product: {torch.prod(tensor)}')\n","print(f'Max: {torch.max(tensor)}')\n","print(f'Min: {torch.min(tensor)}')\n","print(f'Mean: {torch.mean(tensor)}')"]},{"cell_type":"markdown","metadata":{"id":"T2VAOdLLJAiJ"},"source":["We can aggregate values over certain dimensions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2D9O0UzfJAiJ"},"outputs":[],"source":["tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uryxpQuaJAiJ"},"outputs":[],"source":["tensor.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zS7wfrUJAiJ"},"outputs":[],"source":["col_sums = torch.sum(tensor, dim=0)\n","col_sums"]}],"metadata":{"kernelspec":{"display_name":"deeplearning","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}